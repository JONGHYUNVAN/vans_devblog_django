"""
MongoDBì—ì„œ Elasticsearchë¡œ ê²Œì‹œë¬¼ ë°ì´í„° ë™ê¸°í™”

VansDevBlogì˜ MongoDB Post ë°ì´í„°ë¥¼ Elasticsearchë¡œ ë™ê¸°í™”í•˜ì—¬
ê²€ìƒ‰ ê¸°ëŠ¥ì„ í™œì„±í™”í•©ë‹ˆë‹¤.
"""

import logging
from django.core.management.base import BaseCommand, CommandError
from django.utils import timezone
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional

from search.utils.mongodb_client import MongoDBClient
from search.documents import PostDocument
from search.utils.elasticsearch_client import ElasticsearchClient

logger = logging.getLogger('search')


class Command(BaseCommand):
    help = 'MongoDBì˜ ê²Œì‹œë¬¼ì„ Elasticsearchë¡œ ë™ê¸°í™”í•©ë‹ˆë‹¤.'

    def add_arguments(self, parser):
        parser.add_argument(
            '--batch-size',
            type=int,
            default=50,
            help='ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸° (ê¸°ë³¸ê°’: 50)'
        )
        parser.add_argument(
            '--force-all',
            action='store_true',
            help='ë°œí–‰ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ëª¨ë“  ê²Œì‹œë¬¼ì„ ë™ê¸°í™”í•©ë‹ˆë‹¤.'
        )
        parser.add_argument(
            '--incremental',
            action='store_true',
            help='ì¦ë¶„ ë™ê¸°í™”: ìµœê·¼ ì—…ë°ì´íŠ¸ëœ ê²Œì‹œë¬¼ë§Œ ë™ê¸°í™”í•©ë‹ˆë‹¤.'
        )
        parser.add_argument(
            '--days',
            type=int,
            default=7,
            help='ì¦ë¶„ ë™ê¸°í™” ì‹œ í™•ì¸í•  ì¼ìˆ˜ (ê¸°ë³¸ê°’: 7ì¼)'
        )
        parser.add_argument(
            '--dry-run',
            action='store_true',
            help='ì‹¤ì œ ë™ê¸°í™” ì—†ì´ ì²˜ë¦¬í•  ë°ì´í„°ë§Œ í™•ì¸í•©ë‹ˆë‹¤.'
        )
        parser.add_argument(
            '--clear-existing',
            action='store_true',
            help='ê¸°ì¡´ Elasticsearch ë°ì´í„°ë¥¼ ëª¨ë‘ ì‚­ì œí•˜ê³  ìƒˆë¡œ ë™ê¸°í™”í•©ë‹ˆë‹¤.'
        )

    def handle(self, *args, **options):
        self.stdout.write("ğŸ”„ MongoDB â†’ Elasticsearch ë°ì´í„° ë™ê¸°í™” ì‹œì‘")
        self.stdout.write("=" * 60)
        
        try:
            # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            mongo_client = MongoDBClient()
            es_client = ElasticsearchClient()
            
            # ì—°ê²° ìƒíƒœ í™•ì¸
            self._check_connections(mongo_client, es_client)
            
            # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì˜µì…˜)
            if options['clear_existing'] and not options['dry_run']:
                self._clear_existing_data(es_client)
            
            # ë™ê¸°í™” ì‹¤í–‰
            if options['incremental']:
                result = self._incremental_sync(
                    mongo_client, es_client, options
                )
            else:
                result = self._full_sync(
                    mongo_client, es_client, options
                )
            
            # ê²°ê³¼ ì¶œë ¥
            self._print_sync_results(result)
            
            mongo_client.close()
            self.stdout.write(self.style.SUCCESS("\nğŸ‰ ë°ì´í„° ë™ê¸°í™” ì™„ë£Œ!"))
            
        except Exception as e:
            logger.error(f"Data sync failed: {str(e)}")
            raise CommandError(f"ë°ì´í„° ë™ê¸°í™” ì‹¤íŒ¨: {str(e)}")

    def _check_connections(self, mongo_client: MongoDBClient, es_client: ElasticsearchClient):
        """MongoDBì™€ Elasticsearch ì—°ê²° ìƒíƒœ í™•ì¸"""
        self.stdout.write("ğŸ”— ì—°ê²° ìƒíƒœ í™•ì¸...")
        
        if not mongo_client.check_connection():
            raise CommandError("âŒ MongoDB ì—°ê²° ì‹¤íŒ¨!")
        self.stdout.write("âœ… MongoDB ì—°ê²° ì„±ê³µ")
        
        if not es_client.check_connection():
            raise CommandError("âŒ Elasticsearch ì—°ê²° ì‹¤íŒ¨!")
        self.stdout.write("âœ… Elasticsearch ì—°ê²° ì„±ê³µ")

    def _clear_existing_data(self, es_client: ElasticsearchClient):
        """ê¸°ì¡´ Elasticsearch ë°ì´í„° ì‚­ì œ"""
        self.stdout.write("ğŸ—‘ï¸  ê¸°ì¡´ Elasticsearch ë°ì´í„° ì‚­ì œ ì¤‘...")
        
        try:
            # ëª¨ë“  ë¬¸ì„œ ì‚­ì œ
            from elasticsearch_dsl import Search
            s = Search().using(es_client.client)
            response = s.delete()
            self.stdout.write(f"ì‚­ì œëœ ë¬¸ì„œ ìˆ˜: {response.get('deleted', 0)}ê°œ")
        except Exception as e:
            self.stdout.write(self.style.WARNING(f"âš ï¸  ë°ì´í„° ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {str(e)}"))

    def _full_sync(
        self, 
        mongo_client: MongoDBClient, 
        es_client: ElasticsearchClient, 
        options: Dict[str, Any]
    ) -> Dict[str, int]:
        """ì „ì²´ ë™ê¸°í™” ì‹¤í–‰"""
        self.stdout.write("ğŸ“š ì „ì²´ ë™ê¸°í™” ì‹œì‘...")
        
        batch_size = options['batch_size']
        force_all = options['force_all']
        dry_run = options['dry_run']
        
        result = {
            'processed': 0,
            'synced': 0,
            'skipped': 0,
            'errors': 0
        }
        
        # ê²Œì‹œë¬¼ ê°€ì ¸ì˜¤ê¸°
        posts_iterator = (
            mongo_client.get_all_posts(batch_size=batch_size) 
            if force_all 
            else mongo_client.get_all_published_posts(batch_size=batch_size)
        )
        
        batch_posts = []
        
        for post in posts_iterator:
            result['processed'] += 1
            
            # ë°°ì¹˜ ì²˜ë¦¬
            batch_posts.append(post)
            
            if len(batch_posts) >= batch_size:
                batch_result = self._process_batch(batch_posts, dry_run)
                self._update_result(result, batch_result)
                batch_posts = []
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥
                self.stdout.write(
                    f"ì²˜ë¦¬ ì¤‘... {result['processed']}ê°œ | "
                    f"ë™ê¸°í™”: {result['synced']}ê°œ | "
                    f"ê±´ë„ˆëœ€: {result['skipped']}ê°œ"
                )
        
        # ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
        if batch_posts:
            batch_result = self._process_batch(batch_posts, dry_run)
            self._update_result(result, batch_result)
        
        return result

    def _incremental_sync(
        self, 
        mongo_client: MongoDBClient, 
        es_client: ElasticsearchClient, 
        options: Dict[str, Any]
    ) -> Dict[str, int]:
        """ì¦ë¶„ ë™ê¸°í™” ì‹¤í–‰"""
        days = options['days']
        since_date = timezone.now() - timedelta(days=days)
        
        self.stdout.write(f"ğŸ“… ì¦ë¶„ ë™ê¸°í™”: {since_date.strftime('%Y-%m-%d')} ì´í›„ ì—…ë°ì´íŠ¸")
        
        batch_size = options['batch_size']
        dry_run = options['dry_run']
        
        result = {
            'processed': 0,
            'synced': 0,
            'skipped': 0,
            'errors': 0
        }
        
        batch_posts = []
        
        for post in mongo_client.get_posts_updated_since(since_date, batch_size=batch_size):
            result['processed'] += 1
            
            batch_posts.append(post)
            
            if len(batch_posts) >= batch_size:
                batch_result = self._process_batch(batch_posts, dry_run)
                self._update_result(result, batch_result)
                batch_posts = []
                
                self.stdout.write(
                    f"ì²˜ë¦¬ ì¤‘... {result['processed']}ê°œ | "
                    f"ë™ê¸°í™”: {result['synced']}ê°œ"
                )
        
        # ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
        if batch_posts:
            batch_result = self._process_batch(batch_posts, dry_run)
            self._update_result(result, batch_result)
        
        return result

    def _process_batch(self, posts: List[Dict[str, Any]], dry_run: bool) -> Dict[str, int]:
        """ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê²Œì‹œë¬¼ ì²˜ë¦¬"""
        batch_result = {
            'synced': 0,
            'skipped': 0,
            'errors': 0
        }
        
        for post in posts:
            try:
                # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
                if not self._validate_post_data(post):
                    batch_result['skipped'] += 1
                    continue
                
                if dry_run:
                    self.stdout.write(f"[DRY-RUN] ë™ê¸°í™” ì˜ˆì •: {post.get('title', 'No Title')[:30]}...")
                    batch_result['synced'] += 1
                    continue
                
                # Elasticsearch ë¬¸ì„œ ìƒì„± ë° ì €ì¥
                es_doc = self._convert_to_elasticsearch_document(post)
                es_doc.save()
                
                batch_result['synced'] += 1
                logger.debug(f"Synced post: {post.get('_id')}")
                
            except Exception as e:
                batch_result['errors'] += 1
                logger.error(f"Failed to sync post {post.get('_id')}: {str(e)}")
                self.stdout.write(
                    self.style.WARNING(f"âš ï¸  ë™ê¸°í™” ì‹¤íŒ¨: {post.get('title', 'Unknown')[:30]}...")
                )
        
        return batch_result

    def _validate_post_data(self, post: Dict[str, Any]) -> bool:
        """ê²Œì‹œë¬¼ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬"""
        required_fields = ['_id', 'title']
        
        for field in required_fields:
            if not post.get(field):
                logger.warning(f"Missing required field '{field}' in post: {post.get('_id')}")
                return False
        
        return True

    def _convert_to_elasticsearch_document(self, post: Dict[str, Any]) -> PostDocument:
        """MongoDB ë¬¸ì„œë¥¼ Elasticsearch PostDocumentë¡œ ë³€í™˜"""
        
        # ì–¸ì–´ ê°ì§€ (í•œêµ­ì–´/ì˜ì–´)
        title = str(post.get('title', ''))
        content = str(post.get('content', ''))
        text_for_detection = f"{title} {content}"
        language = self._detect_language(text_for_detection)
        
        # ì‘ì„±ì ì •ë³´ ì²˜ë¦¬
        author_info = post.get('author', {})
        if isinstance(author_info, dict):
            author = {
                'user_id': str(author_info.get('_id', '')),
                'username': author_info.get('username', ''),
                'display_name': author_info.get('display_name', ''),
                'profile_image': author_info.get('profile_image', '')
            }
        else:
            author = {
                'user_id': '',
                'username': '',
                'display_name': '',
                'profile_image': ''
            }
        
        # íƒœê·¸ ì²˜ë¦¬
        tags = post.get('tags', [])
        if isinstance(tags, str):
            tags = [tag.strip() for tag in tags.split(',') if tag.strip()]
        elif not isinstance(tags, list):
            tags = []
        
        # ìš”ì•½ë¬¸ ìƒì„±
        summary = post.get('summary', '')
        if not summary and content:
            summary = content[:200] + "..." if len(content) > 200 else content
        
        # PostDocument ìƒì„±
        es_doc = PostDocument(
            meta={'id': str(post['_id'])},
            post_id=str(post['_id']),
            title=title,
            content=content,
            summary=summary,
            slug=post.get('slug', ''),
            theme=post.get('theme', ''),
            category=post.get('category', ''),
            tags=tags,
            author=author,
            published_date=post.get('published_date'),
            updated_date=post.get('updated_date'),
            view_count=post.get('view_count', 0),
            like_count=post.get('like_count', 0),
            comment_count=post.get('comment_count', 0),
            is_published=post.get('is_published', False),
            language=language,
            reading_time=self._calculate_reading_time(content),
            featured_image=post.get('featured_image', ''),
            meta_description=post.get('meta_description', summary[:150]),
            search_boost=1.0
        )
        
        return es_doc

    def _detect_language(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì–¸ì–´ ê°ì§€ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)"""
        if not text or not isinstance(text, str):
            return 'ko'
        
        # í•œê¸€ ë¬¸ì ê°œìˆ˜ ê³„ì‚°
        korean_chars = sum(1 for c in text if '\uac00' <= c <= '\ud7af')
        total_chars = len([c for c in text if c.isalpha()])
        
        if total_chars == 0:
            return 'ko'
        
        korean_ratio = korean_chars / total_chars
        return 'ko' if korean_ratio > 0.3 else 'en'

    def _calculate_reading_time(self, content: str) -> int:
        """ì½ê¸° ì‹œê°„ ê³„ì‚° (ë¶„ ë‹¨ìœ„)"""
        if not content:
            return 1
        
        word_count = len(content.split())
        # í‰ê·  ì½ê¸° ì†ë„: ë¶„ë‹¹ 200ë‹¨ì–´
        reading_time = max(1, word_count // 200)
        return reading_time

    def _update_result(self, total_result: Dict[str, int], batch_result: Dict[str, int]):
        """ë°°ì¹˜ ê²°ê³¼ë¥¼ ì „ì²´ ê²°ê³¼ì— ë°˜ì˜"""
        for key in batch_result:
            if key in total_result:
                total_result[key] += batch_result[key]

    def _print_sync_results(self, result: Dict[str, int]):
        """ë™ê¸°í™” ê²°ê³¼ ì¶œë ¥"""
        self.stdout.write("\n" + "=" * 60)
        self.stdout.write("ğŸ“Š ë™ê¸°í™” ê²°ê³¼:")
        self.stdout.write("-" * 30)
        self.stdout.write(f"ğŸ“ ì²˜ë¦¬ëœ ê²Œì‹œë¬¼: {result['processed']}ê°œ")
        self.stdout.write(f"âœ… ë™ê¸°í™” ì„±ê³µ: {result['synced']}ê°œ")
        self.stdout.write(f"â­ï¸  ê±´ë„ˆëœ€: {result['skipped']}ê°œ")
        self.stdout.write(f"âŒ ì˜¤ë¥˜: {result['errors']}ê°œ")
        
        if result['processed'] > 0:
            success_rate = (result['synced'] / result['processed']) * 100
            self.stdout.write(f"ğŸ¯ ì„±ê³µë¥ : {success_rate:.1f}%")
        
        self.stdout.write("=" * 60)
